"""
å°è¯´ RAG çŸ¥è¯†åº“ - æ–‡æ¡£æ‘„å–æ¨¡å—

èŒè´£ï¼šåŠ è½½ .txt å°è¯´æ–‡ä»¶ â†’ æ–‡æœ¬åˆ†å— â†’ åµŒå…¥å‘é‡åŒ– â†’ å­˜å…¥ ChromaDB
"""
import sys
from pathlib import Path

from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_community.vectorstores import Chroma

from config import (
    DATA_DIR,
    VECTORSTORE_DIR,
    GOOGLE_API_KEY,
    EMBEDDING_MODEL,
    CHUNK_SIZE,
    CHUNK_OVERLAP,
)


def load_documents(data_dir: Path = DATA_DIR) -> list:
    """ä» data/ ç›®å½•åŠ è½½æ‰€æœ‰ .txt æ–‡ä»¶"""
    loader = DirectoryLoader(
        str(data_dir),
        glob="**/*.txt",
        loader_cls=TextLoader,
        loader_kwargs={"encoding": "utf-8"},
        show_progress=True,
    )
    docs = loader.load()
    print(f"âœ… åŠ è½½äº† {len(docs)} ä¸ªæ–‡æ¡£")
    return docs


def split_documents(docs: list) -> list:
    """å°†æ–‡æ¡£åˆ†å‰²æˆè¾ƒå°çš„æ–‡æœ¬å—"""
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=CHUNK_SIZE,
        chunk_overlap=CHUNK_OVERLAP,
        separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼›", "ï¼Œ", " ", ""],
    )
    chunks = splitter.split_documents(docs)
    print(f"âœ… åˆ†å‰²ä¸º {len(chunks)} ä¸ªæ–‡æœ¬å—")
    return chunks


def create_vectorstore(chunks: list) -> Chroma:
    """å°†æ–‡æœ¬å—åµŒå…¥å¹¶å­˜å…¥ ChromaDB"""
    embeddings = GoogleGenerativeAIEmbeddings(
        model=EMBEDDING_MODEL,
        google_api_key=GOOGLE_API_KEY,
    )

    vectorstore = Chroma.from_documents(
        documents=chunks,
        embedding=embeddings,
        persist_directory=str(VECTORSTORE_DIR),
    )
    print(f"âœ… å‘é‡åº“å·²åˆ›å»ºï¼Œå­˜å‚¨äº {VECTORSTORE_DIR}")
    return vectorstore


def ingest(data_dir: Path = DATA_DIR) -> Chroma:
    """æ‰§è¡Œå®Œæ•´çš„æ‘„å–æµç¨‹ï¼šåŠ è½½ â†’ åˆ†å— â†’ å‘é‡åŒ–"""
    if not GOOGLE_API_KEY:
        print("âŒ è¯·è®¾ç½®ç¯å¢ƒå˜é‡ GOOGLE_API_KEY")
        sys.exit(1)

    txt_files = list(data_dir.glob("**/*.txt"))
    if not txt_files:
        print(f"âŒ åœ¨ {data_dir} ä¸­æœªæ‰¾åˆ° .txt æ–‡ä»¶ï¼Œè¯·å…ˆæ”¾å…¥å°è¯´æ–‡ä»¶")
        sys.exit(1)

    print(f"ğŸ“š å¼€å§‹æ‘„å– data/ ç›®å½•ä¸­çš„å°è¯´æ–‡ä»¶...")
    docs = load_documents(data_dir)
    chunks = split_documents(docs)
    vectorstore = create_vectorstore(chunks)
    print("ğŸ‰ æ‘„å–å®Œæˆï¼")
    return vectorstore


if __name__ == "__main__":
    ingest()
